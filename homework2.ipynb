{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUdbx5vhBCsxZpTHD7suqC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunwoo7441/class2025Spring/blob/main/homework2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UPtgsHizGroh",
        "outputId": "425cbdf0-f4ac-43e6-e1e0-8debc6d64ca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "6se6XOpKHCTE",
        "outputId": "871b0311-80fb-43d0-af59-7467668fcc0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from nltk import sent_tokenize, word_tokenize, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "text=\"I know one thing for certain: don't settle for less than what you're capable of, but strive for something bigger. Some of you reading this might identify with this message because it resonates with you on a deeper level. For others, at the end of their tether the message might be nothing more than a trivial pep talk. What I wish to convey irrespective of where you are in your journey is: NEVER settle for less. If you settle for less, you will receive less than you deserve and convince yourself you are justified to receive it. If you have not achieved the success you deserve and are considering giving up, will you regret it in a few years or decades from now? Only you can answer that, but you should carve out time to discover your motivation for pursuing your goals. It’s a fact, if you don’t know what you want you’ll get what life hands you and it may not be in your best interest, affirms author Larry Weidel: “Winners know that if you don’t figure out what you want, you’ll get whatever life hands you.” The key is to develop a powerful vision of what you want and hold that image in your mind. Nurture it daily and give it life by taking purposeful action towards it.\"\n",
        "sentences = sent_tokenize(text) # NLTK 함수\n",
        "total_documents = len(sentences)\n",
        "print(total_documents)"
      ],
      "metadata": {
        "id": "8KdyeXl0HGGT",
        "outputId": "0e75bf3e-341b-4618-9303-e9b8a999d7fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_frequency_matrix(sentences):\n",
        "    \"\"\"\n",
        "    문장 리스트를 입력받아 단어 빈도 행렬을 생성하는 함수입니다.\n",
        "\n",
        "    Args:\n",
        "        sentences (list): 문장 리스트\n",
        "\n",
        "    Returns:\n",
        "        dict: 단어 빈도 행렬 (key: 문장[:15], value: 단어 빈도표)\n",
        "    \"\"\"\n",
        "    frequency_matrix = {}  # 단어 빈도 행렬을 저장할 딕셔너리를 초기화\n",
        "    stopWords = set(stopwords.words(\"english\"))  # 영어 불용어 목록을 가져와서 set 자료형으로 변환\n",
        "    ps = PorterStemmer()  # PorterStemmer 객체를 생성\n",
        "\n",
        "    for sent in sentences:  # 입력된 문장 리스트에서 각 문장에 대해 반복\n",
        "        freq_table = {}  # 현재 문장의 단어 빈도를 저장할 딕셔너리를 초기화\n",
        "        words = word_tokenize(sent)  # 문장을 단어 단위로 분리\n",
        "\n",
        "        for word in words:  # 분리된 단어 리스트에서 각 단어에 대해 반복\n",
        "            word = word.lower()  # 단어를 소문자로 변환\n",
        "            word = ps.stem(word)  # PorterStemmer를 사용하여 단어의 어간을 추출\n",
        "            if word in stopWords:  # 만약 단어가 불용어라면 건너뜀\n",
        "                continue\n",
        "\n",
        "            if word in freq_table:  # 만약 단어가 이미 freq_table에 있다면 빈도를 1 증가\n",
        "                freq_table[word] += 1\n",
        "            else:  # 만약 단어가 freq_table에 없다면 빈도를 1로 설정\n",
        "                freq_table[word] = 1\n",
        "\n",
        "        frequency_matrix[sent[:15]] = freq_table\n",
        "        # 현재 문장의 처음 15자를 key로, 단어 빈도표를 value로 하여 frequency_matrix에 저장\n",
        "\n",
        "    return frequency_matrix  # 생성된 단어 빈도 행렬을 반환"
      ],
      "metadata": {
        "id": "dJ7A5x7GHJba"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#documents에 등장하는 단어들을 위해 테이블 생성\n",
        "\n",
        "def _create_documents_per_words(freq_matrix):\n",
        "    \"\"\"\n",
        "    단어 빈도 행렬을 입력받아 단어별 문서 수 테이블을 생성하는 함수입니다.\n",
        "\n",
        "    Args:\n",
        "        freq_matrix (dict): 단어 빈도 행렬 (key: 문장[:15], value: 단어 빈도표)\n",
        "\n",
        "    Returns:\n",
        "        dict: 단어별 문서 수 테이블 (key: 단어, value: 문서 수)\n",
        "    \"\"\"\n",
        "    word_per_doc_table = {}  # 단어별 문서 수를 저장할 딕셔너리를 초기화\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():  # 단어 빈도 행렬의 각 문장과 단어 빈도표에 대해 반복\n",
        "        for word, count in f_table.items():  # 단어 빈도표의 각 단어와 빈도에 대해 반복\n",
        "            if word in word_per_doc_table:\n",
        "            # 만약 단어가 이미 word_per_doc_table에 있다면 문서 수를 1 증가\n",
        "                word_per_doc_table[word] += 1\n",
        "            else:\n",
        "              # 만약 단어가 word_per_doc_table에 없다면 문서 수를 1로 설정\n",
        "                word_per_doc_table[word] = 1\n",
        "\n",
        "    return word_per_doc_table  # 생성된 단어별 문서 수 테이블을 반환"
      ],
      "metadata": {
        "id": "FH9HHnTJHPYa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _score_sentences(tf_idf_matrix) -> dict:\n",
        "    \"\"\"\n",
        "    문장의 단어 TF-IDF 값을 기반으로 문장 점수를 계산하는 함수입니다.\n",
        "\n",
        "    각 문장에 대해 불용어가 아닌 단어들의 TF-IDF 값을 합산하고,\n",
        "    문장 내 단어 개수로 나누어 점수를 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        tf_idf_matrix (dict): TF-IDF 행렬 (key: 문장, value: 단어별 TF-IDF 값)\n",
        "\n",
        "    Returns:\n",
        "        dict: 문장별 점수 (key: 문장, value: 점수)\n",
        "    \"\"\"\n",
        "\n",
        "    sentenceValue = {}  # 문장별 점수를 저장할 딕셔너리를 초기화\n",
        "\n",
        "    for sent, f_table in tf_idf_matrix.items():\n",
        "      # TF-IDF 행렬의 각 문장과 단어별 TF-IDF 값에 대해 반복\n",
        "        total_score_per_sentence = 0\n",
        "        # 현재 문장의 총 점수를 0으로 초기화\n",
        "\n",
        "        count_words_in_sentence = len(f_table)  # 현재 문장의 단어 개수를 계산\n",
        "        for word, score in f_table.items():\n",
        "            # 단어별 TF-IDF 값에 대해 반복\n",
        "            total_score_per_sentence += score  # 현재 문장의 총 점수에 단어의 TF-IDF 값을 더함\n",
        "\n",
        "        # 현재 문장의 총 점수를 단어 개수로 나누어 문장 점수를 계산하고 sentenceValue에 저장\n",
        "        sentenceValue[sent] = total_score_per_sentence / count_words_in_sentence\n",
        "\n",
        "    return sentenceValue  # 계산된 문장별 점수를 반환"
      ],
      "metadata": {
        "id": "p5d8RB3-HVp6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_tf_matrix(freq_matrix):\n",
        "    \"\"\"\n",
        "    단어 빈도 행렬을 입력받아 TF 행렬을 생성하는 함수입니다.\n",
        "\n",
        "    Args:\n",
        "        freq_matrix (dict): 단어 빈도 행렬 (key: 문장[:15], value: 단어 빈도표)\n",
        "\n",
        "    Returns:\n",
        "        dict: TF 행렬 (key: 문장, value: 단어별 TF 값)\n",
        "    \"\"\"\n",
        "    tf_matrix = {}  # TF 행렬을 저장할 딕셔너리를 초기화\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():\n",
        "        # 단어 빈도 행렬의 각 문장과 단어 빈도표에 대해 반복\n",
        "        tf_table = {}  # 현재 문장의 단어별 TF 값을 저장할 딕셔너리를 초기화\n",
        "\n",
        "        count_words_in_sentence = len(f_table)  # 현재 문장의 단어 개수를 계산\n",
        "        for word, count in f_table.items():  # 단어 빈도표의 각 단어와 빈도에 대해 반복\n",
        "            # 단어의 빈도를 문장 내 단어 개수로 나누어 TF 값을 계산하고 tf_table에 저장\n",
        "            tf_table[word] = count / count_words_in_sentence\n",
        "\n",
        "        tf_matrix[sent] = tf_table\n",
        "        # 현재 문장을 key로, 단어별 TF 값을 value로 하여 tf_matrix에 저장\n",
        "\n",
        "    return tf_matrix  # 생성된 TF 행렬을 반환"
      ],
      "metadata": {
        "id": "vgLMS4XkHaP7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents):\n",
        "    \"\"\"\n",
        "    단어 빈도 행렬과 단어별 문서 수 테이블, 전체 문서 수를 입력받아 IDF 행렬을 생성하는 함수입니다.\n",
        "\n",
        "    Args:\n",
        "        freq_matrix (dict): 단어 빈도 행렬 (key: 문장[:15], value: 단어 빈도표)\n",
        "        count_doc_per_words (dict): 단어별 문서 수 테이블 (key: 단어, value: 문서 수)\n",
        "        total_documents (int): 전체 문서 수\n",
        "\n",
        "    Returns:\n",
        "        dict: IDF 행렬 (key: 문장, value: 단어별 IDF 값)\n",
        "    \"\"\"\n",
        "    idf_matrix = {}  # IDF 행렬을 저장할 딕셔너리를 초기화\n",
        "\n",
        "    for sent, f_table in freq_matrix.items():\n",
        "        # 단어 빈도 행렬의 각 문장과 단어 빈도표에 대해 반복\n",
        "        idf_table = {}  # 현재 문장의 단어별 IDF 값을 저장할 딕셔너리를 초기화\n",
        "\n",
        "        for word in f_table.keys():  # 단어 빈도표의 각 단어에 대해 반복\n",
        "            # 전체 문서 수를 단어가 등장하는 문서 수로 나눈 값에 log10을 취하여 IDF 값을 계산하고 idf_table에 저장\n",
        "            idf_table[word] = math.log10(total_documents / float(count_doc_per_words[word]))\n",
        "\n",
        "        idf_matrix[sent] = idf_table\n",
        "        # 현재 문장을 key로, 단어별 IDF 값을 value로 하여 idf_matrix에 저장\n",
        "\n",
        "    return idf_matrix  # 생성된 IDF 행렬을 반환합니다."
      ],
      "metadata": {
        "id": "Ga8Rr2maHb-y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _create_tf_idf_matrix(tf_matrix, idf_matrix):\n",
        "    tf_idf_matrix = {}\n",
        "\n",
        "    for (sent1, f_table1), (sent2, f_table2) in zip(tf_matrix.items(), idf_matrix.items()):\n",
        "\n",
        "        tf_idf_table = {}\n",
        "\n",
        "        for (word1, value1), (word2, value2) in zip(f_table1.items(),\n",
        "                                                    f_table2.items()):\n",
        "            # here, keys are the same in both the table\n",
        "            tf_idf_table[word1] = float(value1 * value2)\n",
        "\n",
        "        tf_idf_matrix[sent1] = tf_idf_table\n",
        "\n",
        "    return tf_idf_matrix"
      ],
      "metadata": {
        "id": "-5nGaBRrHjbC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 각 문장에 있는 단어의 빈도 행렬 생성\n",
        "freq_matrix = _create_frequency_matrix(sentences)\n",
        "\n",
        "# 2 TF 계산 및 행렬 생성\n",
        "tf_matrix = _create_tf_matrix(freq_matrix)\n",
        "print(\"\\n\\ntf:\\n\",tf_matrix)\n",
        "\n",
        "# 3 documents에 등장하는 단어들을 위해 행렬 생성\n",
        "count_doc_per_words = _create_documents_per_words(freq_matrix)\n",
        "\n",
        "'''\n",
        "Inverse document frequency (IDF) is how unique or rare a word is.\n",
        "'''\n",
        "# 4 IDF 계산 및 행렬 생성\n",
        "idf_matrix = _create_idf_matrix(freq_matrix, count_doc_per_words, total_documents)\n",
        "print(\"\\n\\nidf:\\n\", idf_matrix)\n",
        "\n",
        "# 5 TF-IDF 계산 및 행렬 생성\n",
        "tf_idf_matrix = _create_tf_idf_matrix(tf_matrix, idf_matrix)\n",
        "print(\"\\n\\ntf-idf:\\n\",tf_idf_matrix)\n"
      ],
      "metadata": {
        "id": "4thi8mSVHnlq",
        "outputId": "de58de1d-7efe-4b55-ec5c-139a72b8a918",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "tf:\n",
            " {'I know one thin': {'know': 0.06666666666666667, 'one': 0.06666666666666667, 'thing': 0.06666666666666667, 'certain': 0.06666666666666667, ':': 0.06666666666666667, \"n't\": 0.06666666666666667, 'settl': 0.06666666666666667, 'less': 0.06666666666666667, \"'re\": 0.06666666666666667, 'capabl': 0.06666666666666667, ',': 0.06666666666666667, 'strive': 0.06666666666666667, 'someth': 0.06666666666666667, 'bigger': 0.06666666666666667, '.': 0.06666666666666667}, 'Some of you rea': {'read': 0.1, 'thi': 0.2, 'might': 0.1, 'identifi': 0.1, 'messag': 0.1, 'becaus': 0.1, 'reson': 0.1, 'deeper': 0.1, 'level': 0.1, '.': 0.1}, 'For others, at ': {',': 0.1, 'end': 0.1, 'tether': 0.1, 'messag': 0.1, 'might': 0.1, 'noth': 0.1, 'trivial': 0.1, 'pep': 0.1, 'talk': 0.1, '.': 0.1}, 'What I wish to ': {'wish': 0.1111111111111111, 'convey': 0.1111111111111111, 'irrespect': 0.1111111111111111, 'journey': 0.1111111111111111, ':': 0.1111111111111111, 'never': 0.1111111111111111, 'settl': 0.1111111111111111, 'less': 0.1111111111111111, '.': 0.1111111111111111}, 'If you settle f': {'settl': 0.125, 'less': 0.25, ',': 0.125, 'receiv': 0.25, 'deserv': 0.125, 'convinc': 0.125, 'justifi': 0.125, '.': 0.125}, 'If you have not': {'achiev': 0.1, 'success': 0.1, 'deserv': 0.1, 'consid': 0.1, 'give': 0.1, ',': 0.1, 'regret': 0.1, 'year': 0.1, 'decad': 0.1, '?': 0.1}, 'Only you can an': {'onli': 0.1, 'answer': 0.1, ',': 0.1, 'carv': 0.1, 'time': 0.1, 'discov': 0.1, 'motiv': 0.1, 'pursu': 0.1, 'goal': 0.1, '.': 0.1}, 'It’s a fact, if': {'’': 0.16666666666666666, 'fact': 0.03333333333333333, ',': 0.1, 'know': 0.06666666666666667, 'want': 0.1, 'get': 0.06666666666666667, 'life': 0.06666666666666667, 'hand': 0.06666666666666667, 'may': 0.03333333333333333, 'best': 0.03333333333333333, 'interest': 0.03333333333333333, 'affirm': 0.03333333333333333, 'author': 0.03333333333333333, 'larri': 0.03333333333333333, 'weidel': 0.03333333333333333, ':': 0.03333333333333333, '“': 0.03333333333333333, 'winner': 0.03333333333333333, 'figur': 0.03333333333333333, 'whatev': 0.03333333333333333, 'you.': 0.03333333333333333, '”': 0.03333333333333333, 'key': 0.03333333333333333, 'develop': 0.03333333333333333, 'power': 0.03333333333333333, 'vision': 0.03333333333333333, 'hold': 0.03333333333333333, 'imag': 0.03333333333333333, 'mind': 0.03333333333333333, '.': 0.03333333333333333}, 'Nurture it dail': {'nurtur': 0.1111111111111111, 'daili': 0.1111111111111111, 'give': 0.1111111111111111, 'life': 0.1111111111111111, 'take': 0.1111111111111111, 'purpos': 0.1111111111111111, 'action': 0.1111111111111111, 'toward': 0.1111111111111111, '.': 0.1111111111111111}}\n",
            "\n",
            "\n",
            "idf:\n",
            " {'I know one thin': {'know': 0.6532125137753437, 'one': 0.9542425094393249, 'thing': 0.9542425094393249, 'certain': 0.9542425094393249, ':': 0.47712125471966244, \"n't\": 0.9542425094393249, 'settl': 0.47712125471966244, 'less': 0.47712125471966244, \"'re\": 0.9542425094393249, 'capabl': 0.9542425094393249, ',': 0.17609125905568124, 'strive': 0.9542425094393249, 'someth': 0.9542425094393249, 'bigger': 0.9542425094393249, '.': 0.05115252244738129}, 'Some of you rea': {'read': 0.9542425094393249, 'thi': 0.9542425094393249, 'might': 0.6532125137753437, 'identifi': 0.9542425094393249, 'messag': 0.6532125137753437, 'becaus': 0.9542425094393249, 'reson': 0.9542425094393249, 'deeper': 0.9542425094393249, 'level': 0.9542425094393249, '.': 0.05115252244738129}, 'For others, at ': {',': 0.17609125905568124, 'end': 0.9542425094393249, 'tether': 0.9542425094393249, 'messag': 0.6532125137753437, 'might': 0.6532125137753437, 'noth': 0.9542425094393249, 'trivial': 0.9542425094393249, 'pep': 0.9542425094393249, 'talk': 0.9542425094393249, '.': 0.05115252244738129}, 'What I wish to ': {'wish': 0.9542425094393249, 'convey': 0.9542425094393249, 'irrespect': 0.9542425094393249, 'journey': 0.9542425094393249, ':': 0.47712125471966244, 'never': 0.9542425094393249, 'settl': 0.47712125471966244, 'less': 0.47712125471966244, '.': 0.05115252244738129}, 'If you settle f': {'settl': 0.47712125471966244, 'less': 0.47712125471966244, ',': 0.17609125905568124, 'receiv': 0.9542425094393249, 'deserv': 0.6532125137753437, 'convinc': 0.9542425094393249, 'justifi': 0.9542425094393249, '.': 0.05115252244738129}, 'If you have not': {'achiev': 0.9542425094393249, 'success': 0.9542425094393249, 'deserv': 0.6532125137753437, 'consid': 0.9542425094393249, 'give': 0.6532125137753437, ',': 0.17609125905568124, 'regret': 0.9542425094393249, 'year': 0.9542425094393249, 'decad': 0.9542425094393249, '?': 0.9542425094393249}, 'Only you can an': {'onli': 0.9542425094393249, 'answer': 0.9542425094393249, ',': 0.17609125905568124, 'carv': 0.9542425094393249, 'time': 0.9542425094393249, 'discov': 0.9542425094393249, 'motiv': 0.9542425094393249, 'pursu': 0.9542425094393249, 'goal': 0.9542425094393249, '.': 0.05115252244738129}, 'It’s a fact, if': {'’': 0.9542425094393249, 'fact': 0.9542425094393249, ',': 0.17609125905568124, 'know': 0.6532125137753437, 'want': 0.9542425094393249, 'get': 0.9542425094393249, 'life': 0.6532125137753437, 'hand': 0.9542425094393249, 'may': 0.9542425094393249, 'best': 0.9542425094393249, 'interest': 0.9542425094393249, 'affirm': 0.9542425094393249, 'author': 0.9542425094393249, 'larri': 0.9542425094393249, 'weidel': 0.9542425094393249, ':': 0.47712125471966244, '“': 0.9542425094393249, 'winner': 0.9542425094393249, 'figur': 0.9542425094393249, 'whatev': 0.9542425094393249, 'you.': 0.9542425094393249, '”': 0.9542425094393249, 'key': 0.9542425094393249, 'develop': 0.9542425094393249, 'power': 0.9542425094393249, 'vision': 0.9542425094393249, 'hold': 0.9542425094393249, 'imag': 0.9542425094393249, 'mind': 0.9542425094393249, '.': 0.05115252244738129}, 'Nurture it dail': {'nurtur': 0.9542425094393249, 'daili': 0.9542425094393249, 'give': 0.6532125137753437, 'life': 0.6532125137753437, 'take': 0.9542425094393249, 'purpos': 0.9542425094393249, 'action': 0.9542425094393249, 'toward': 0.9542425094393249, '.': 0.05115252244738129}}\n",
            "\n",
            "\n",
            "tf-idf:\n",
            " {'I know one thin': {'know': 0.04354750091835625, 'one': 0.06361616729595498, 'thing': 0.06361616729595498, 'certain': 0.06361616729595498, ':': 0.03180808364797749, \"n't\": 0.06361616729595498, 'settl': 0.03180808364797749, 'less': 0.03180808364797749, \"'re\": 0.06361616729595498, 'capabl': 0.06361616729595498, ',': 0.01173941727037875, 'strive': 0.06361616729595498, 'someth': 0.06361616729595498, 'bigger': 0.06361616729595498, '.': 0.0034101681631587524}, 'Some of you rea': {'read': 0.09542425094393249, 'thi': 0.19084850188786498, 'might': 0.06532125137753438, 'identifi': 0.09542425094393249, 'messag': 0.06532125137753438, 'becaus': 0.09542425094393249, 'reson': 0.09542425094393249, 'deeper': 0.09542425094393249, 'level': 0.09542425094393249, '.': 0.00511525224473813}, 'For others, at ': {',': 0.017609125905568124, 'end': 0.09542425094393249, 'tether': 0.09542425094393249, 'messag': 0.06532125137753438, 'might': 0.06532125137753438, 'noth': 0.09542425094393249, 'trivial': 0.09542425094393249, 'pep': 0.09542425094393249, 'talk': 0.09542425094393249, '.': 0.00511525224473813}, 'What I wish to ': {'wish': 0.1060269454932583, 'convey': 0.1060269454932583, 'irrespect': 0.1060269454932583, 'journey': 0.1060269454932583, ':': 0.05301347274662915, 'never': 0.1060269454932583, 'settl': 0.05301347274662915, 'less': 0.05301347274662915, '.': 0.005683613605264587}, 'If you settle f': {'settl': 0.059640156839957804, 'less': 0.11928031367991561, ',': 0.022011407381960155, 'receiv': 0.23856062735983122, 'deserv': 0.08165156422191797, 'convinc': 0.11928031367991561, 'justifi': 0.11928031367991561, '.': 0.006394065305922661}, 'If you have not': {'achiev': 0.09542425094393249, 'success': 0.09542425094393249, 'deserv': 0.06532125137753438, 'consid': 0.09542425094393249, 'give': 0.06532125137753438, ',': 0.017609125905568124, 'regret': 0.09542425094393249, 'year': 0.09542425094393249, 'decad': 0.09542425094393249, '?': 0.09542425094393249}, 'Only you can an': {'onli': 0.09542425094393249, 'answer': 0.09542425094393249, ',': 0.017609125905568124, 'carv': 0.09542425094393249, 'time': 0.09542425094393249, 'discov': 0.09542425094393249, 'motiv': 0.09542425094393249, 'pursu': 0.09542425094393249, 'goal': 0.09542425094393249, '.': 0.00511525224473813}, 'It’s a fact, if': {'’': 0.15904041823988746, 'fact': 0.03180808364797749, ',': 0.017609125905568124, 'know': 0.04354750091835625, 'want': 0.09542425094393249, 'get': 0.06361616729595498, 'life': 0.04354750091835625, 'hand': 0.06361616729595498, 'may': 0.03180808364797749, 'best': 0.03180808364797749, 'interest': 0.03180808364797749, 'affirm': 0.03180808364797749, 'author': 0.03180808364797749, 'larri': 0.03180808364797749, 'weidel': 0.03180808364797749, ':': 0.015904041823988746, '“': 0.03180808364797749, 'winner': 0.03180808364797749, 'figur': 0.03180808364797749, 'whatev': 0.03180808364797749, 'you.': 0.03180808364797749, '”': 0.03180808364797749, 'key': 0.03180808364797749, 'develop': 0.03180808364797749, 'power': 0.03180808364797749, 'vision': 0.03180808364797749, 'hold': 0.03180808364797749, 'imag': 0.03180808364797749, 'mind': 0.03180808364797749, '.': 0.0017050840815793762}, 'Nurture it dail': {'nurtur': 0.1060269454932583, 'daili': 0.1060269454932583, 'give': 0.07257916819726042, 'life': 0.07257916819726042, 'take': 0.1060269454932583, 'purpos': 0.1060269454932583, 'action': 0.1060269454932583, 'toward': 0.1060269454932583, '.': 0.005683613605264587}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "Ao6EnLzeHqv6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docA = \"The car is driven on the road\"\n",
        "docB = \"The truck is driven on the highway\""
      ],
      "metadata": {
        "id": "PMBvv3oGHtNi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "xw1uKOS8HvtC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = tfidf.fit_transform([docA, docB])"
      ],
      "metadata": {
        "id": "UffWXS_gHyIp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = tfidf.get_feature_names_out()\n",
        "# TF-IDF 벡터라이저에서 특성 이름(단어) 목록을 가져옴\n",
        "for col in response.nonzero()[1]:\n",
        "    # 응답 행렬에서 0이 아닌 값의 열 인덱스에 대해 반복\n",
        "    # nonzero() 메서드는 행렬에서 0이 아닌 값의 인덱스를 반환\n",
        "    # [1] : 열 인덱스\n",
        "    print(feature_names[col], ' - ', response[0, col])  # 특성 이름과 해당 값을 출력\n",
        "    # 현재 열 인덱스(col)에 해당하는 단어(feature_names[col])와 그 단어의 TF-IDF 값(response[0, col])을 출력"
      ],
      "metadata": {
        "id": "uz6F-da6H0qK",
        "outputId": "a92ec010-7332-4b7d-e246-81102a28ff6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the  -  0.6043795515372431\n",
            "car  -  0.42471718586982765\n",
            "is  -  0.30218977576862155\n",
            "driven  -  0.30218977576862155\n",
            "on  -  0.30218977576862155\n",
            "road  -  0.42471718586982765\n",
            "the  -  0.6043795515372431\n",
            "is  -  0.30218977576862155\n",
            "driven  -  0.30218977576862155\n",
            "on  -  0.30218977576862155\n",
            "truck  -  0.0\n",
            "highway  -  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tf-idf 값이 높을수록 다른 문서에 잘 언급되지 않은 단어(my, love, hate, hobby, is, passion)인 것을 알 수 있다.\n",
        "# tf-idf 값이 낮을수록 다른 문서에 잘 언급하는 단어(I, dogs, and, knitting)인 것을 알 수 있다."
      ],
      "metadata": {
        "id": "8iggvJ0xH7dy"
      }
    }
  ]
}